{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/opt/anaconda/envs/ai/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "DEBUG:matplotlib:CACHEDIR=/home/ubuntu/.cache/matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /home/ubuntu/.cache/matplotlib/fontList.json\n",
      "DEBUG:matplotlib.backends:backend agg version v2.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling weight norm\n",
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 50\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDEFAULT_FIT_EPOCHS: 1000\n",
      "\tDEFAULT_LEARN_RATE: 0.0001\n",
      "\tDEFAULT_TRAIN_ITERS: 5000\n",
      "\tDEFAULT_Z_DIM: 128\n",
      "\tDIAGNOSIS_LEARN_RATE: 0.01\n",
      "\tDIM: 64\n",
      "\tDISC_FILTER_SIZE: 5\n",
      "\tLAMBDA: 10\n",
      "\tLAMBDA_2: 2.0\n",
      "\tOUTPUT_DIM: 784\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from alphai_watson.performance import GANPerformanceAnalysis\n",
    "from alphai_watson.transformer import NullTransformer\n",
    "from alphai_rickandmorty_oracle.datasource.mnist import MNISTDataSource\n",
    "from alphai_rickandmorty_oracle.detective import RickAndMortyDetective\n",
    "from alphai_rickandmorty_oracle.model_mnist import RickAndMorty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MNIST Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Start file parsing\n",
      "DEBUG:root:end file parsing\n",
      "DEBUG:root:Start file parsing\n",
      "DEBUG:root:end file parsing\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../tests/resources'\n",
    "\n",
    "abnormal_digit = 0\n",
    "\n",
    "# Train and test data file\n",
    "train_data_file = os.path.join(file_path, 'mnist_data_train_abnormalclass-{}.hd5'.format(abnormal_digit))\n",
    "test_data_file = os.path.join(file_path, 'mnist_data_test_abnormalclass-{}.hd5'.format(abnormal_digit))\n",
    "\n",
    "# Model parameters\n",
    "n_sensors = 28\n",
    "n_timesteps = 784 // n_sensors\n",
    "\n",
    "train_data_source = MNISTDataSource(source_file=train_data_file, \n",
    "                                    transformer=NullTransformer(number_of_timesteps=n_timesteps,\n",
    "                                                                number_of_sensors=n_sensors))\n",
    "test_data_source = MNISTDataSource(source_file=test_data_file,\n",
    "                                   transformer=NullTransformer(number_of_timesteps=n_timesteps,\n",
    "                                                               number_of_sensors=n_sensors))\n",
    "\n",
    "train_data = train_data_source.get_train_data('NORMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22402091, -0.9306218 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size=(2)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Starting session\n",
      "DEBUG:root:Start training loop...\n",
      "INFO:root:Initialising Model\n",
      "INFO:root:Training iteration 0 of 500\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/anaconda/envs/ai/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\ttrain disc cost\t4.448973178863525\ttime\t1.5029473304748535\n",
      "iter 1\ttrain disc cost\t4.078559875488281\ttime\t0.5121018886566162\n",
      "iter 2\ttrain disc cost\t3.6282434463500977\ttime\t0.39653921127319336\n",
      "iter 3\ttrain disc cost\t3.2144811153411865\ttime\t0.3991217613220215\n",
      "iter 4\ttrain disc cost\t2.8161511421203613\ttime\t0.3966710567474365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving fake samples to png: [[4.4489777e-01 3.3024967e-01 3.0298778e-01 ... 3.8713755e-05\n",
      "  1.0057024e-04 8.6436031e-04]\n",
      " [4.4287777e-01 3.4936598e-01 3.0335483e-01 ... 1.1523318e-04\n",
      "  2.7655842e-04 2.0732493e-03]\n",
      " [4.2080510e-01 3.3166012e-01 2.5407052e-01 ... 1.9293455e-05\n",
      "  5.3430918e-05 4.3736753e-04]\n",
      " ...\n",
      " [4.3437430e-01 3.3959484e-01 2.6679581e-01 ... 5.1089341e-05\n",
      "  1.9232633e-04 1.2045383e-03]\n",
      " [4.4132638e-01 3.0945745e-01 2.5402907e-01 ... 1.1197264e-05\n",
      "  6.4925989e-05 3.4866590e-04]\n",
      " [4.3560097e-01 3.1633222e-01 2.5955385e-01 ... 4.6262194e-05\n",
      "  1.6314983e-04 1.4763810e-03]]\n",
      "INFO:root:Training iteration 100 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 99\ttrain disc cost\t-0.22218067944049835\ttime\t0.39823265075683595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving fake samples to png: [[3.79183702e-02 2.03327113e-03 2.00124853e-03 ... 2.49480195e-07\n",
      "  1.07168842e-06 2.22474023e-06]\n",
      " [4.70315814e-02 3.28988186e-03 2.87445448e-03 ... 1.21397920e-06\n",
      "  4.57488795e-06 1.02515687e-05]\n",
      " [3.08882501e-02 1.86576496e-03 1.40997313e-03 ... 1.08692355e-07\n",
      "  4.29164288e-07 8.87650742e-07]\n",
      " ...\n",
      " [2.58488152e-02 1.46688230e-03 1.19498896e-03 ... 5.12603492e-07\n",
      "  2.94917504e-06 6.11738460e-06]\n",
      " [2.61848271e-02 1.14410440e-03 1.00085442e-03 ... 3.92370545e-08\n",
      "  3.87484789e-07 3.87008726e-07]\n",
      " [3.95275727e-02 1.95313338e-03 1.69305189e-03 ... 4.37539541e-07\n",
      "  2.30128967e-06 6.50285892e-06]]\n",
      "INFO:root:Training iteration 200 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 199\ttrain disc cost\t-0.1313803642988205\ttime\t0.39064417362213133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving fake samples to png: [[2.8243230e-04 1.6987351e-05 1.2207779e-05 ... 3.6036621e-10\n",
      "  9.4901544e-09 1.6202771e-08]\n",
      " [3.6671275e-04 2.6121745e-05 1.6468655e-05 ... 3.3105367e-09\n",
      "  6.2246286e-08 1.2402785e-07]\n",
      " [1.7804011e-04 1.3447468e-05 6.8548011e-06 ... 1.0548542e-10\n",
      "  3.6842918e-09 6.2038010e-09]\n",
      " ...\n",
      " [1.0084806e-04 8.0837926e-06 4.8154225e-06 ... 1.2428658e-09\n",
      "  4.2814428e-08 7.7799029e-08]\n",
      " [6.7747183e-05 3.5963369e-06 2.2597510e-06 ... 2.4845927e-11\n",
      "  1.9463833e-09 1.2929158e-09]\n",
      " [2.5689817e-04 1.3056019e-05 7.8546536e-06 ... 9.2804642e-10\n",
      "  2.5639551e-08 5.8758950e-08]]\n",
      "INFO:root:Training iteration 300 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 299\ttrain disc cost\t-0.15441879630088806\ttime\t0.3929048252105713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving fake samples to png: [[7.8635430e-06 7.0277033e-06 4.9657700e-07 ... 1.4894560e-11\n",
      "  3.1708267e-10 3.6440068e-10]\n",
      " [9.4492143e-06 9.7603242e-06 6.3952535e-07 ... 1.9128797e-10\n",
      "  3.0117091e-09 4.1360604e-09]\n",
      " [3.2676401e-06 4.3497307e-06 1.9650075e-07 ... 3.9576714e-12\n",
      "  1.1605189e-10 1.3282216e-10]\n",
      " ...\n",
      " [2.5825943e-06 4.4938229e-06 2.2927611e-07 ... 6.8780773e-11\n",
      "  2.0602064e-09 2.6496394e-09]\n",
      " [7.8839071e-07 1.0932749e-06 4.7537647e-08 ... 6.4420046e-13\n",
      "  4.0255677e-11 1.8083916e-11]\n",
      " [4.8201186e-06 4.4037497e-06 2.3408617e-07 ... 4.8743856e-11\n",
      "  1.1223431e-09 1.5982106e-09]]\n",
      "INFO:root:Training iteration 400 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 399\ttrain disc cost\t-0.17418472468852997\ttime\t0.3950315308570862\n"
     ]
    }
   ],
   "source": [
    "model_dir = './mnist_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "batch_size = 64\n",
    "output_dimensions = 784\n",
    "train_iters = 500\n",
    "plot_save_path = model_dir\n",
    "\n",
    "model = RickAndMorty(batch_size=batch_size, \n",
    "                     output_dimensions=output_dimensions, \n",
    "                     train_iters=train_iters,\n",
    "                     plot_save_path=plot_save_path)\n",
    "\n",
    "detective = RickAndMortyDetective(model_configuration={\n",
    "    'model': model,\n",
    "    'batch_size': batch_size,\n",
    "    'output_dimensions': output_dimensions,\n",
    "    'train_iters': train_iters,\n",
    "    'save_path' : '{}/MNIST-abnormalclass-{}'.format(model_dir, abnormal_digit),\n",
    "    'plot_save_path' : plot_save_path\n",
    "})\n",
    "\n",
    "detective.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detective = RickAndMortyDetective(model_configuration={\n",
    "#     'batch_size': 64,\n",
    "#     'output_dimensions': 784,\n",
    "#     'train_iters': 300,\n",
    "#     'load_path' : '{}/MNIST-abnormalclass-{}'.format(model_dir, abnormal_digit),\n",
    "#     'plot_save_path' : model_dir\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "test_data_normal = test_data_source.get_train_data('NORMAL')\n",
    "test_data_abnormal = test_data_source.get_train_data('ABNORMAL')\n",
    "test_data = test_data_source.get_train_data('ALL')\n",
    "\n",
    "# Ground truth for ABNORMAL data is 1 , ground truth for NORMAL data is 0\n",
    "n1 = np.ones(len(test_data_abnormal.data))\n",
    "n2 = np.zeros(len(test_data_normal.data))\n",
    "expected_truth = np.hstack((n1, n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_result = detective.detect(test_data)\n",
    "\n",
    "roc_score = GANPerformanceAnalysis({}).analyse(\n",
    "  detection_result=detection_result.data,\n",
    "  expected_truth=expected_truth\n",
    ")\n",
    "\n",
    "print('ROC Score: {}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ; Compared ground truth to np.rint(detection_result.data), which rounds probability <0.5 to 0 and >0.5 to 1\n",
    "clf_rep = precision_recall_fscore_support(expected_truth, np.rint(detection_result.data))\n",
    "out_dict = {\n",
    "             \"precision\" :clf_rep[0].round(2)\n",
    "            ,\"recall\" : clf_rep[1].round(2)\n",
    "            ,\"f1-score\" : clf_rep[2].round(2)\n",
    "            ,\"support\" : clf_rep[3]\n",
    "            }\n",
    "df_out = pd.DataFrame(out_dict, index = ['NORMAL', 'ABNORMAL'])\n",
    "avg_tot = (df_out.apply(lambda x: round(x.mean(), 2) if x.name != \"support\" else  round(x.sum(), 2)).to_frame().T)\n",
    "avg_tot.index = [\"avg/total\"]\n",
    "df_out = df_out.append(avg_tot)\n",
    "print(df_out)\n",
    "\n",
    "# Save Classification report to CSV (Optional)\n",
    "# df_out.to_csv('classification_report_digit-{}.csv'.format(abnormal_digit), sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
