{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from alphai_watson.performance import GANPerformanceAnalysis\n",
    "from alphai_watson.transformer import NullTransformer\n",
    "from alphai_rickandmorty_oracle.datasource.mnist import MNISTDataSource\n",
    "from alphai_rickandmorty_oracle.detective import RickAndMortyDetective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MNIST Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Start file parsing\n",
      "DEBUG:root:end file parsing\n",
      "DEBUG:root:Start file parsing\n",
      "DEBUG:root:end file parsing\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../tests/resources'\n",
    "\n",
    "abnormal_digit = 0\n",
    "\n",
    "# Train and test data file\n",
    "train_data_file = os.path.join(file_path, 'mnist_data_train_abnormalclass-{}.hd5'.format(abnormal_digit))\n",
    "test_data_file = os.path.join(file_path, 'mnist_data_test_abnormalclass-{}.hd5'.format(abnormal_digit))\n",
    "\n",
    "# Model parameters\n",
    "n_sensors = 28\n",
    "n_timesteps = 784 // n_sensors\n",
    "\n",
    "train_data_source = MNISTDataSource(source_file=train_data_file, \n",
    "                                    transformer=NullTransformer(number_of_timesteps=n_timesteps,\n",
    "                                                                number_of_sensors=n_sensors))\n",
    "test_data_source = MNISTDataSource(source_file=test_data_file,\n",
    "                                   transformer=NullTransformer(number_of_timesteps=n_timesteps,\n",
    "                                                               number_of_sensors=n_sensors))\n",
    "\n",
    "train_data = train_data_source.get_train_data('NORMAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Starting session\n",
      "DEBUG:root:Start training loop...\n",
      "INFO:root:Initialising Model\n",
      "INFO:root:Training iteration 0 of 300\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/anaconda/envs/ai/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\ttrain disc cost\t4.037641525268555\ttime\t1.510230541229248\n",
      "iter 1\ttrain disc cost\t3.8670847415924072\ttime\t0.5102806091308594\n",
      "iter 2\ttrain disc cost\t3.4915263652801514\ttime\t0.39618349075317383\n",
      "iter 3\ttrain disc cost\t3.1009411811828613\ttime\t0.39540553092956543\n",
      "iter 4\ttrain disc cost\t2.637146234512329\ttime\t0.39788055419921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 10 of 300\n",
      "INFO:root:Training iteration 20 of 300\n",
      "INFO:root:Training iteration 30 of 300\n",
      "INFO:root:Training iteration 40 of 300\n",
      "INFO:root:Training iteration 50 of 300\n",
      "INFO:root:Training iteration 60 of 300\n",
      "INFO:root:Training iteration 70 of 300\n",
      "INFO:root:Training iteration 80 of 300\n",
      "INFO:root:Training iteration 90 of 300\n",
      "INFO:root:Saving fake samples to png: [[4.0527284e-01 2.4000376e-01 3.0115387e-01 ... 8.9863385e-04\n",
      "  9.3013444e-04 9.0060709e-03]\n",
      " [4.2366964e-01 2.9641557e-01 3.3525011e-01 ... 1.7667129e-03\n",
      "  1.3773292e-03 1.5553150e-02]\n",
      " [4.2145753e-01 2.7865052e-01 3.3675086e-01 ... 3.0118148e-03\n",
      "  2.3665472e-03 2.4681127e-02]\n",
      " ...\n",
      " [4.1139325e-01 2.3799224e-01 3.2147908e-01 ... 1.1823700e-03\n",
      "  9.7324932e-04 8.1918174e-03]\n",
      " [4.1284037e-01 2.6070544e-01 3.1745490e-01 ... 6.2933320e-04\n",
      "  3.6564804e-04 6.5768426e-03]\n",
      " [4.1086984e-01 2.5339261e-01 3.1878462e-01 ... 1.0698074e-03\n",
      "  9.6572412e-04 6.6419370e-03]]\n",
      "INFO:root:Training iteration 100 of 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 99\ttrain disc cost\t-0.17775702476501465\ttime\t0.3984001310248124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 110 of 300\n",
      "INFO:root:Training iteration 120 of 300\n",
      "INFO:root:Training iteration 130 of 300\n",
      "INFO:root:Training iteration 140 of 300\n",
      "INFO:root:Training iteration 150 of 300\n",
      "INFO:root:Training iteration 160 of 300\n",
      "INFO:root:Training iteration 170 of 300\n",
      "INFO:root:Training iteration 180 of 300\n",
      "INFO:root:Training iteration 190 of 300\n",
      "INFO:root:Saving fake samples to png: [[1.3422823e-02 1.2413806e-03 1.3170124e-03 ... 4.1285674e-07\n",
      "  1.4309966e-06 3.2356380e-05]\n",
      " [3.5850018e-02 4.9649724e-03 3.9995620e-03 ... 1.2199120e-06\n",
      "  3.2905812e-06 8.2162398e-05]\n",
      " [2.7280426e-02 4.1583166e-03 3.9525921e-03 ... 4.6929413e-06\n",
      "  1.0976233e-05 2.6004211e-04]\n",
      " ...\n",
      " [1.7542917e-02 1.6914802e-03 2.1081713e-03 ... 6.3477677e-07\n",
      "  1.7679511e-06 4.1119751e-05]\n",
      " [1.8112201e-02 2.2311225e-03 2.3569188e-03 ... 1.0988447e-07\n",
      "  2.8662546e-07 1.6359489e-05]\n",
      " [2.0872641e-02 2.6567273e-03 2.9331450e-03 ... 4.9102954e-07\n",
      "  1.4841416e-06 2.5545311e-05]]\n",
      "INFO:root:Training iteration 200 of 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 199\ttrain disc cost\t-0.11982018500566483\ttime\t0.39054878234863283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 210 of 300\n",
      "INFO:root:Training iteration 220 of 300\n",
      "INFO:root:Training iteration 230 of 300\n",
      "INFO:root:Training iteration 240 of 300\n",
      "INFO:root:Training iteration 250 of 300\n",
      "INFO:root:Training iteration 260 of 300\n",
      "INFO:root:Training iteration 270 of 300\n",
      "INFO:root:Training iteration 280 of 300\n",
      "INFO:root:Training iteration 290 of 300\n",
      "INFO:root:Saving fake samples to png: [[4.98269255e-05 3.14861177e-06 4.12205463e-06 ... 3.08888071e-09\n",
      "  2.56038248e-08 3.21569985e-07]\n",
      " [3.43296066e-04 2.66075112e-05 2.26329685e-05 ... 5.83007687e-09\n",
      "  4.29774119e-08 6.37947721e-07]\n",
      " [2.54455837e-04 2.81456851e-05 3.18975617e-05 ... 9.42354603e-08\n",
      "  4.41803792e-07 6.04461684e-06]\n",
      " ...\n",
      " [9.63019411e-05 6.20263563e-06 9.92296373e-06 ... 4.84061990e-09\n",
      "  3.32511227e-08 4.44717614e-07]\n",
      " [5.13663290e-05 4.15056684e-06 5.90219543e-06 ... 2.51597299e-10\n",
      "  2.14234119e-09 6.83629935e-08]\n",
      " [1.03021135e-04 8.50947254e-06 1.23131476e-05 ... 2.31774000e-09\n",
      "  1.88606144e-08 1.94293534e-07]]\n",
      "DEBUG:root:Training complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 299\ttrain disc cost\t-0.1573355793952942\ttime\t0.3923739767074585\n"
     ]
    }
   ],
   "source": [
    "model_dir = './mnist_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "detective = RickAndMortyDetective(model_configuration={\n",
    "    'batch_size': 64,\n",
    "    'output_dimensions': 784,\n",
    "    'train_iters': 300,\n",
    "    'save_path' : '{}/MNIST-abnormalclass-{}'.format(model_dir, abnormal_digit),\n",
    "    'plot_save_path' : model_dir\n",
    "})\n",
    "\n",
    "detective.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable ano_z already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/ubuntu/alpha-i/code/detective-gan-rick-and-morty/alphai_rickandmorty_oracle/model_mnist.py\", line 69, in __init__\n    self.ano_z = tf.get_variable('ano_z', shape=[1, self.z_dim], dtype=tf.float32, initializer=z_init)\n  File \"/home/ubuntu/alpha-i/code/detective-gan-rick-and-morty/alphai_rickandmorty_oracle/detective.py\", line 54, in __init__\n    plot_save_path=plot_save_path, load_path=load_path)\n  File \"<ipython-input-3-18d99b8064b3>\", line 11, in <module>\n    'plot_save_path' : model_dir\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ea7d30ef982c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 'save_path' : 'trained_models/MNIST-abnormalclass-{}'.format(abnormal_digit),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'load_path'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'{}/MNIST-abnormalclass-{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabnormal_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m'plot_save_path'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m })\n",
      "\u001b[0;32m~/alpha-i/code/detective-gan-rick-and-morty/alphai_rickandmorty_oracle/detective.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_configuration)\u001b[0m\n\u001b[1;32m     52\u001b[0m         )\n\u001b[1;32m     53\u001b[0m         self.model = RickAndMorty(batch_size=batch_size, output_dimensions=output_dimensions, train_iters=train_iters,\n\u001b[0;32m---> 54\u001b[0;31m                                   plot_save_path=plot_save_path, load_path=load_path)\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/alpha-i/code/detective-gan-rick-and-morty/alphai_rickandmorty_oracle/model_mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, output_dimensions, learning_rate, train_iters, z_dim, plot_save_path, load_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mz_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mano_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ano_z'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mano_z_optimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomaly_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_diagnosis_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1205\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/opt/anaconda/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/opt/anaconda/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/opt/anaconda/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    740\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 742\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    743\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable ano_z already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/ubuntu/alpha-i/code/detective-gan-rick-and-morty/alphai_rickandmorty_oracle/model_mnist.py\", line 69, in __init__\n    self.ano_z = tf.get_variable('ano_z', shape=[1, self.z_dim], dtype=tf.float32, initializer=z_init)\n  File \"/home/ubuntu/alpha-i/code/detective-gan-rick-and-morty/alphai_rickandmorty_oracle/detective.py\", line 54, in __init__\n    plot_save_path=plot_save_path, load_path=load_path)\n  File \"<ipython-input-3-18d99b8064b3>\", line 11, in <module>\n    'plot_save_path' : model_dir\n"
     ]
    }
   ],
   "source": [
    "# detective = RickAndMortyDetective(model_configuration={\n",
    "#     'batch_size': 64,\n",
    "#     'output_dimensions': 784,\n",
    "#     'train_iters': 300,\n",
    "#     'load_path' : '{}/MNIST-abnormalclass-{}'.format(model_dir, abnormal_digit),\n",
    "#     'plot_save_path' : model_dir\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "test_data_normal = test_data_source.get_train_data('NORMAL')\n",
    "test_data_abnormal = test_data_source.get_train_data('ABNORMAL')\n",
    "test_data = test_data_source.get_train_data('ALL')\n",
    "\n",
    "# Ground truth for ABNORMAL data is 1 , ground truth for NORMAL data is 0\n",
    "n1 = np.ones(len(test_data_abnormal.data))\n",
    "n2 = np.zeros(len(test_data_normal.data))\n",
    "expected_truth = np.hstack((n1, n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running detector on <alphai_watson.datasource.Sample object at 0x7f04784a7908>\n",
      "Exception ignored in: <bound method RickAndMorty.__del__ of <alphai_rickandmorty_oracle.model_mnist.RickAndMorty object at 0x7f04e5450c18>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/alpha-i/code/detective-gan-rick-and-morty/alphai_rickandmorty_oracle/model_mnist.py\", line 74, in __del__\n",
      "    self.tf_session.close()\n",
      "  File \"/opt/anaconda/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1627, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/opt/anaconda/envs/ai/lib/python3.6/contextlib.py\", line 88, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/anaconda/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4345, in get_controller\n",
      "    type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'tensorflow.python.client.session.InteractiveSession'> objects\n",
      "INFO:root:Detection completed in 1.342307273298502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4639372268149566\n"
     ]
    }
   ],
   "source": [
    "detection_result = detective.detect(test_data)\n",
    "\n",
    "roc_score = GANPerformanceAnalysis({}).analyse(\n",
    "  detection_result=detection_result.data,\n",
    "  expected_truth=expected_truth\n",
    ")\n",
    "\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           f1-score  precision  recall  support\n",
      "NORMAL         0.41       0.59    0.32  12620.0\n",
      "ABNORMAL       0.42       0.33    0.60   6903.0\n",
      "avg/total      0.42       0.46    0.46  19523.0\n"
     ]
    }
   ],
   "source": [
    "# Save ; Compared ground truth to np.rint(detection_result.data), which rounds probability <0.5 to 0 and >0.5 to 1\n",
    "clf_rep = precision_recall_fscore_support(expected_truth, np.rint(detection_result.data))\n",
    "out_dict = {\n",
    "             \"precision\" :clf_rep[0].round(2)\n",
    "            ,\"recall\" : clf_rep[1].round(2)\n",
    "            ,\"f1-score\" : clf_rep[2].round(2)\n",
    "            ,\"support\" : clf_rep[3]\n",
    "            }\n",
    "df_out = pd.DataFrame(out_dict, index = ['NORMAL', 'ABNORMAL'])\n",
    "avg_tot = (df_out.apply(lambda x: round(x.mean(), 2) if x.name != \"support\" else  round(x.sum(), 2)).to_frame().T)\n",
    "avg_tot.index = [\"avg/total\"]\n",
    "df_out = df_out.append(avg_tot)\n",
    "print(df_out)\n",
    "\n",
    "# Save Classification report to CSV (Optional)\n",
    "# df_out.to_csv('classification_report_digit-{}.csv'.format(abnormal_digit), sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
