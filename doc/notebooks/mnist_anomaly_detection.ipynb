{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/opt/anaconda/envs/ai/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "DEBUG:matplotlib:CACHEDIR=/home/ubuntu/.cache/matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /home/ubuntu/.cache/matplotlib/fontList.json\n",
      "DEBUG:matplotlib.backends:backend agg version v2.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling weight norm\n",
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 50\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDEFAULT_FIT_EPOCHS: 1000\n",
      "\tDEFAULT_LEARN_RATE: 0.0001\n",
      "\tDEFAULT_TRAIN_ITERS: 5000\n",
      "\tDEFAULT_Z_DIM: 128\n",
      "\tDIAGNOSIS_LEARN_RATE: 0.01\n",
      "\tDIM: 64\n",
      "\tDISC_FILTER_SIZE: 5\n",
      "\tLAMBDA: 10\n",
      "\tLAMBDA_2: 2.0\n",
      "\tOUTPUT_DIM: 784\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from alphai_watson.performance import GANPerformanceAnalysis\n",
    "from alphai_watson.transformer import NullTransformer\n",
    "from alphai_rickandmorty_oracle.datasource.mnist import MNISTDataSource\n",
    "from alphai_rickandmorty_oracle.detective import RickAndMortyDetective\n",
    "from alphai_rickandmorty_oracle.model_mnist import RickAndMorty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MNIST Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Start file parsing\n",
      "DEBUG:root:end file parsing\n",
      "DEBUG:root:Start file parsing\n",
      "DEBUG:root:end file parsing\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../tests/resources'\n",
    "\n",
    "abnormal_digit = 0\n",
    "\n",
    "# Train and test data file\n",
    "train_data_file = os.path.join(file_path, 'mnist_data_train_abnormalclass-{}.hd5'.format(abnormal_digit))\n",
    "test_data_file = os.path.join(file_path, 'mnist_data_test_abnormalclass-{}.hd5'.format(abnormal_digit))\n",
    "\n",
    "# Model parameters\n",
    "n_sensors = 28\n",
    "n_timesteps = 784 // n_sensors\n",
    "\n",
    "train_data_source = MNISTDataSource(source_file=train_data_file, \n",
    "                                    transformer=NullTransformer(number_of_timesteps=n_timesteps,\n",
    "                                                                number_of_sensors=n_sensors))\n",
    "test_data_source = MNISTDataSource(source_file=test_data_file,\n",
    "                                   transformer=NullTransformer(number_of_timesteps=n_timesteps,\n",
    "                                                               number_of_sensors=n_sensors))\n",
    "\n",
    "train_data = train_data_source.get_train_data('NORMAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Starting session\n",
      "DEBUG:root:Start training loop...\n",
      "INFO:root:Initialising Model\n",
      "INFO:root:Training iteration 0 of 500\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/anaconda/envs/ai/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\ttrain disc cost\t4.175182342529297\ttime\t1.471437931060791\n",
      "iter 1\ttrain disc cost\t3.9061384201049805\ttime\t0.5063550472259521\n",
      "iter 2\ttrain disc cost\t3.3714137077331543\ttime\t0.39545321464538574\n",
      "iter 3\ttrain disc cost\t3.286400079727173\ttime\t0.39770030975341797\n",
      "iter 4\ttrain disc cost\t2.917823553085327\ttime\t0.3981661796569824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 10 of 500\n",
      "INFO:root:Training iteration 20 of 500\n",
      "INFO:root:Training iteration 30 of 500\n",
      "INFO:root:Training iteration 40 of 500\n",
      "INFO:root:Training iteration 50 of 500\n",
      "INFO:root:Training iteration 60 of 500\n",
      "INFO:root:Training iteration 70 of 500\n",
      "INFO:root:Training iteration 80 of 500\n",
      "INFO:root:Training iteration 90 of 500\n",
      "INFO:root:Saving fake samples to png: [[3.6590439e-01 2.0064412e-01 2.2247709e-01 ... 1.8403502e-05\n",
      "  4.3979974e-04 1.0389431e-02]\n",
      " [3.6786816e-01 1.9464168e-01 2.2587135e-01 ... 1.8845632e-05\n",
      "  6.1430095e-04 1.1284796e-02]\n",
      " [3.5417131e-01 1.8135026e-01 2.1309792e-01 ... 1.5082329e-05\n",
      "  4.3484016e-04 1.1254670e-02]\n",
      " ...\n",
      " [3.7132490e-01 2.0138793e-01 2.2871152e-01 ... 1.9919158e-05\n",
      "  4.0194459e-04 1.4225681e-02]\n",
      " [3.8211232e-01 2.3122169e-01 2.6105803e-01 ... 6.7956571e-05\n",
      "  1.2835683e-03 1.7909879e-02]\n",
      " [3.8765338e-01 2.5124362e-01 2.6587242e-01 ... 7.2952018e-05\n",
      "  1.2529304e-03 2.2525899e-02]]\n",
      "INFO:root:Training iteration 100 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 99\ttrain disc cost\t-0.10305924713611603\ttime\t0.3980048505883468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 110 of 500\n",
      "INFO:root:Training iteration 120 of 500\n",
      "INFO:root:Training iteration 130 of 500\n",
      "INFO:root:Training iteration 140 of 500\n",
      "INFO:root:Training iteration 150 of 500\n",
      "INFO:root:Training iteration 160 of 500\n",
      "INFO:root:Training iteration 170 of 500\n",
      "INFO:root:Training iteration 180 of 500\n",
      "INFO:root:Training iteration 190 of 500\n",
      "INFO:root:Saving fake samples to png: [[1.82593502e-02 1.21762720e-03 1.02231523e-03 ... 1.64841950e-07\n",
      "  1.44603746e-07 1.23878664e-04]\n",
      " [1.84627231e-02 1.25326158e-03 1.12420146e-03 ... 1.08136724e-07\n",
      "  1.22157161e-07 9.43169871e-05]\n",
      " [1.38942627e-02 8.05405667e-04 7.11829402e-04 ... 9.05294684e-08\n",
      "  8.63299618e-08 9.86486411e-05]\n",
      " ...\n",
      " [1.78632550e-02 1.23435154e-03 1.06488972e-03 ... 1.26109143e-07\n",
      "  1.23452566e-07 1.34308037e-04]\n",
      " [2.38237530e-02 2.66049756e-03 2.41387403e-03 ... 9.62696163e-07\n",
      "  1.21864230e-06 3.62134393e-04]\n",
      " [2.46977340e-02 2.72607757e-03 2.30587879e-03 ... 7.52619144e-07\n",
      "  6.18390345e-07 3.40026512e-04]]\n",
      "INFO:root:Training iteration 200 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 199\ttrain disc cost\t-0.09602370858192444\ttime\t0.3898245167732239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 210 of 500\n",
      "INFO:root:Training iteration 220 of 500\n",
      "INFO:root:Training iteration 230 of 500\n",
      "INFO:root:Training iteration 240 of 500\n",
      "INFO:root:Training iteration 250 of 500\n",
      "INFO:root:Training iteration 260 of 500\n",
      "INFO:root:Training iteration 270 of 500\n",
      "INFO:root:Training iteration 280 of 500\n",
      "INFO:root:Training iteration 290 of 500\n",
      "INFO:root:Saving fake samples to png: [[1.2616682e-04 9.2172268e-06 4.2545576e-06 ... 1.2342832e-09\n",
      "  7.1833389e-10 6.2240701e-07]\n",
      " [1.2507998e-04 9.7687989e-06 4.9492269e-06 ... 8.2685081e-10\n",
      "  6.9700767e-10 4.6209942e-07]\n",
      " [6.7839632e-05 4.6997757e-06 2.2851850e-06 ... 5.0295207e-10\n",
      "  4.2566042e-10 3.8583869e-07]\n",
      " ...\n",
      " [1.2484168e-04 1.0123809e-05 4.9501327e-06 ... 7.9530665e-10\n",
      "  6.1686123e-10 6.0367023e-07]\n",
      " [2.3056871e-04 3.3919721e-05 1.8642464e-05 ... 1.5431477e-08\n",
      "  1.6574484e-08 3.9200067e-06]\n",
      " [2.0853025e-04 2.7070591e-05 1.3555482e-05 ... 9.3362704e-09\n",
      "  6.7054646e-09 2.9007347e-06]]\n",
      "INFO:root:Training iteration 300 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 299\ttrain disc cost\t-0.15806829929351807\ttime\t0.39258101224899294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 310 of 500\n",
      "INFO:root:Training iteration 320 of 500\n",
      "INFO:root:Training iteration 330 of 500\n",
      "INFO:root:Training iteration 340 of 500\n",
      "INFO:root:Training iteration 350 of 500\n",
      "INFO:root:Training iteration 360 of 500\n",
      "INFO:root:Training iteration 370 of 500\n",
      "INFO:root:Training iteration 380 of 500\n",
      "INFO:root:Training iteration 390 of 500\n",
      "INFO:root:Saving fake samples to png: [[6.5214967e-06 1.1285581e-06 5.1809610e-07 ... 4.8095364e-11\n",
      "  6.1417711e-11 4.8849937e-08]\n",
      " [5.5073747e-06 1.0383102e-06 5.2269468e-07 ... 3.1440441e-11\n",
      "  6.2029902e-11 3.5039825e-08]\n",
      " [2.3246071e-06 4.0648894e-07 1.9286152e-07 ... 1.6636281e-11\n",
      "  3.5477975e-11 2.6076915e-08]\n",
      " ...\n",
      " [1.0192445e-05 2.0462285e-06 1.0287082e-06 ... 3.2015082e-11\n",
      "  5.2672519e-11 4.7861526e-08]\n",
      " [9.2403470e-06 3.1483296e-06 1.6982580e-06 ... 9.6510400e-10\n",
      "  2.3360696e-09 4.5467416e-07]\n",
      " [1.2791144e-05 3.8813751e-06 1.9629636e-06 ... 4.7657250e-10\n",
      "  7.4118001e-10 2.8243051e-07]]\n",
      "INFO:root:Training iteration 400 of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 399\ttrain disc cost\t-0.1799074113368988\ttime\t0.3946001148223877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training iteration 410 of 500\n",
      "INFO:root:Training iteration 420 of 500\n",
      "INFO:root:Training iteration 430 of 500\n",
      "INFO:root:Training iteration 440 of 500\n",
      "INFO:root:Training iteration 450 of 500\n",
      "INFO:root:Training iteration 460 of 500\n",
      "INFO:root:Training iteration 470 of 500\n",
      "INFO:root:Training iteration 480 of 500\n",
      "INFO:root:Training iteration 490 of 500\n",
      "INFO:root:Saving fake samples to png: [[1.5769763e-06 4.6158851e-07 2.4898793e-07 ... 1.1538572e-11\n",
      "  2.6810233e-11 1.7124965e-08]\n",
      " [1.5969948e-06 5.1380403e-07 3.0642107e-07 ... 7.6636119e-12\n",
      "  2.7309934e-11 1.2468958e-08]\n",
      " [7.3049659e-07 2.2393375e-07 1.2927948e-07 ... 3.7187601e-12\n",
      "  1.5354823e-11 8.6514209e-09]\n",
      " ...\n",
      " [2.6833559e-06 9.2102783e-07 5.3548160e-07 ... 7.5889763e-12\n",
      "  2.2995736e-11 1.6645195e-08]\n",
      " [2.4162291e-06 1.3812421e-06 8.7966345e-07 ... 2.8326178e-10\n",
      "  1.1866772e-09 1.8616582e-07]\n",
      " [4.9948508e-06 2.5287932e-06 1.5136678e-06 ... 1.2514119e-10\n",
      "  3.6341918e-10 1.0745638e-07]]\n",
      "DEBUG:root:Training complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 499\ttrain disc cost\t-0.19283579289913177\ttime\t0.38950712203979493\n"
     ]
    }
   ],
   "source": [
    "model_dir = './mnist_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "batch_size = 64\n",
    "output_dimensions = 784\n",
    "train_iters = 500\n",
    "plot_save_path = model_dir\n",
    "\n",
    "model = RickAndMorty(batch_size=batch_size, \n",
    "                     output_dimensions=output_dimensions, \n",
    "                     train_iters=train_iters,\n",
    "                     plot_save_path=plot_save_path)\n",
    "\n",
    "detective = RickAndMortyDetective(model_configuration={\n",
    "    'model': model,\n",
    "    'batch_size': batch_size,\n",
    "    'output_dimensions': output_dimensions,\n",
    "    'train_iters': train_iters,\n",
    "    'save_path' : '{}/MNIST-abnormalclass-{}'.format(model_dir, abnormal_digit),\n",
    "    'plot_save_path' : plot_save_path\n",
    "})\n",
    "\n",
    "detective.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detective = RickAndMortyDetective(model_configuration={\n",
    "#     'batch_size': 64,\n",
    "#     'output_dimensions': 784,\n",
    "#     'train_iters': 300,\n",
    "#     'load_path' : '{}/MNIST-abnormalclass-{}'.format(model_dir, abnormal_digit),\n",
    "#     'plot_save_path' : model_dir\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "test_data_normal = test_data_source.get_train_data('NORMAL')\n",
    "test_data_abnormal = test_data_source.get_train_data('ABNORMAL')\n",
    "test_data = test_data_source.get_train_data('ALL')\n",
    "\n",
    "# Ground truth for ABNORMAL data is 1 , ground truth for NORMAL data is 0\n",
    "n1 = np.ones(len(test_data_abnormal.data))\n",
    "n2 = np.zeros(len(test_data_normal.data))\n",
    "expected_truth = np.hstack((n1, n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running detector on <alphai_watson.datasource.Sample object at 0x7fa37868e390>\n",
      "INFO:root:Detection completed in 1.0699957609176636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4709560176528132\n"
     ]
    }
   ],
   "source": [
    "detection_result = detective.detect(test_data)\n",
    "\n",
    "roc_score = GANPerformanceAnalysis({}).analyse(\n",
    "  detection_result=detection_result.data,\n",
    "  expected_truth=expected_truth\n",
    ")\n",
    "\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           f1-score  precision  recall  support\n",
      "NORMAL         0.33       0.57    0.23  12620.0\n",
      "ABNORMAL       0.44       0.33    0.69   6903.0\n",
      "avg/total      0.38       0.45    0.46  19523.0\n"
     ]
    }
   ],
   "source": [
    "# Save ; Compared ground truth to np.rint(detection_result.data), which rounds probability <0.5 to 0 and >0.5 to 1\n",
    "clf_rep = precision_recall_fscore_support(expected_truth, np.rint(detection_result.data))\n",
    "out_dict = {\n",
    "             \"precision\" :clf_rep[0].round(2)\n",
    "            ,\"recall\" : clf_rep[1].round(2)\n",
    "            ,\"f1-score\" : clf_rep[2].round(2)\n",
    "            ,\"support\" : clf_rep[3]\n",
    "            }\n",
    "df_out = pd.DataFrame(out_dict, index = ['NORMAL', 'ABNORMAL'])\n",
    "avg_tot = (df_out.apply(lambda x: round(x.mean(), 2) if x.name != \"support\" else  round(x.sum(), 2)).to_frame().T)\n",
    "avg_tot.index = [\"avg/total\"]\n",
    "df_out = df_out.append(avg_tot)\n",
    "print(df_out)\n",
    "\n",
    "# Save Classification report to CSV (Optional)\n",
    "# df_out.to_csv('classification_report_digit-{}.csv'.format(abnormal_digit), sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
